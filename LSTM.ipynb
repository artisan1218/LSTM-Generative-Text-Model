{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Text Model using LSTM\n",
    "## Chengyuan Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t9rM-Cq3rQEj"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "93d52QaETIKm",
    "outputId": "1c9697f5-2c3e-4bb3-c0ca-de1401eee1df"
   },
   "outputs": [],
   "source": [
    "#Read files and concat them into one corpus\n",
    "filenames = ['TPP.txt', 'TAM.txt', 'MLOE.txt', 'OKEWFSMP.txt'] \n",
    "remove = dict.fromkeys(map(ord, string.punctuation), ' ')\n",
    "with open('corpus.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        #translate will remove the punctuation\n",
    "        #lower will convert all upper case letter to lower case'\n",
    "        #split and join will remove all extra spaces, left only 1 space between words\n",
    "        #so corpusFile will only contains lower case letter\n",
    "        content = open(fname, 'r', encoding = 'ascii', errors='ignore').read()\n",
    "        processed_content = ' '.join(content.translate(remove).lower().split())\n",
    "        outfile.write(processed_content)\n",
    "\n",
    "#store the file as different type\n",
    "corpus_file = open('corpus.txt', 'r')\n",
    "corpus_text = corpus_file.read()\n",
    "corpus_set = set(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ftbt0JxEsKDd"
   },
   "outputs": [],
   "source": [
    "#the original char-code(index) pair\n",
    "corpus_char_code_dict = dict()\n",
    "corpus_code_char_dict = dict()\n",
    "for index, char in enumerate(sorted(corpus_set)):\n",
    "    corpus_char_code_dict[char] = index\n",
    "    corpus_code_char_dict[index] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VDgeWzh-sMCu"
   },
   "outputs": [],
   "source": [
    "#scaled[0,1] char-ascii code pair\n",
    "corpus_char_scaled_dict = dict()\n",
    "corpus_scaled_char_dict = dict()\n",
    "ascii_code_array = np.array(list(corpus_char_code_dict.values())).reshape(-1,1)\n",
    "scaled_value_list = MinMaxScaler().fit_transform(ascii_code_array)\n",
    "for i in range(len(corpus_char_code_dict)):\n",
    "    key = list(corpus_char_code_dict.keys())[i]\n",
    "    scaled_value = scaled_value_list[i][0]\n",
    "    corpus_char_scaled_dict[key] = scaled_value\n",
    "    corpus_scaled_char_dict[scaled_value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x8FrDsOOsNGk"
   },
   "outputs": [],
   "source": [
    "# making x data and y data\n",
    "window_size = 100 #use first 99 characters in this window to predict the 100th character\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(corpus_text) - window_size): \n",
    "    x_char = corpus_text[i:i+window_size-1]  #first 99 characters in this window\n",
    "    y_char = corpus_text[i+window_size-1]  #the 100th character of this window\n",
    "    x_data.append([corpus_char_scaled_dict[x] for x in x_char]) # 99 scaled char as x\n",
    "    y_data.append(corpus_char_code_dict[y_char])  # last char as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://stackoverflow.com/questions/61550026/valueerror-shapes-none-1-and-none-3-are-incompatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXBNEaRxsO-j",
    "outputId": "af2be809-c701-4152-f26c-9b610b16f172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1530941, 99, 1)\n",
      "(1530941, 37)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(x_data)\n",
    "x_data = np.reshape(x_data, (x_data.shape[0], x_data.shape[1], 1))\n",
    "y_data = keras.utils.to_categorical(y_data, num_classes=len(corpus_char_code_dict))\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypTmUdHwsRFV",
    "outputId": "d9baebaf-d073-4d64-b042-852aeed6f216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 37)                9509      \n",
      "=================================================================\n",
      "Total params: 273,701\n",
      "Trainable params: 273,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = keras.models.Sequential()\n",
    "lstm.add(keras.layers.LSTM(units=256, input_shape=(x_data.shape[1], x_data.shape[2])))\n",
    "lstm.add(keras.layers.Dense(y_data.shape[1], activation=\"softmax\"))\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "#### 1. Model configuration\n",
    "- https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "- https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
    "- https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class\n",
    "\n",
    "#### 2. Weights keeping using checkpoints\n",
    "- https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "- https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miwLcmx9sTwQ",
    "outputId": "f9e80b0b-70af-4657-e3a1-7ad888a0691f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "47842/47842 [==============================] - 355s 7ms/step - loss: 2.2072 - accuracy: 0.3557\n",
      "Epoch 2/30\n",
      "47842/47842 [==============================] - 355s 7ms/step - loss: 1.7631 - accuracy: 0.4883\n",
      "Epoch 3/30\n",
      "47842/47842 [==============================] - 354s 7ms/step - loss: 1.6102 - accuracy: 0.5303\n",
      "Epoch 4/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.5247 - accuracy: 0.5544\n",
      "Epoch 5/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.4669 - accuracy: 0.5701\n",
      "Epoch 6/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.4253 - accuracy: 0.5814\n",
      "Epoch 7/30\n",
      "47842/47842 [==============================] - 352s 7ms/step - loss: 1.3926 - accuracy: 0.5900\n",
      "Epoch 8/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.3660 - accuracy: 0.5975\n",
      "Epoch 9/30\n",
      "47842/47842 [==============================] - 354s 7ms/step - loss: 1.3440 - accuracy: 0.6033\n",
      "Epoch 10/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.3259 - accuracy: 0.6083\n",
      "Epoch 11/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.3106 - accuracy: 0.6120\n",
      "Epoch 12/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2972 - accuracy: 0.6151\n",
      "Epoch 13/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2857 - accuracy: 0.6184\n",
      "Epoch 14/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2747 - accuracy: 0.6211\n",
      "Epoch 15/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2647 - accuracy: 0.6238\n",
      "Epoch 16/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2565 - accuracy: 0.6263\n",
      "Epoch 17/30\n",
      "47842/47842 [==============================] - 354s 7ms/step - loss: 1.2485 - accuracy: 0.6282\n",
      "Epoch 18/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2410 - accuracy: 0.6304\n",
      "Epoch 19/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2345 - accuracy: 0.6319\n",
      "Epoch 20/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2288 - accuracy: 0.6333\n",
      "Epoch 21/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2207 - accuracy: 0.6356\n",
      "Epoch 22/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2186 - accuracy: 0.6360\n",
      "Epoch 23/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2138 - accuracy: 0.6372\n",
      "Epoch 24/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2088 - accuracy: 0.6388\n",
      "Epoch 25/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.2047 - accuracy: 0.6396\n",
      "Epoch 26/30\n",
      "47842/47842 [==============================] - 352s 7ms/step - loss: 1.2005 - accuracy: 0.6409\n",
      "Epoch 27/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.1959 - accuracy: 0.6424\n",
      "Epoch 28/30\n",
      "47842/47842 [==============================] - 352s 7ms/step - loss: 1.1920 - accuracy: 0.6432\n",
      "Epoch 29/30\n",
      "47842/47842 [==============================] - 352s 7ms/step - loss: 1.1881 - accuracy: 0.6444\n",
      "Epoch 30/30\n",
      "47842/47842 [==============================] - 353s 7ms/step - loss: 1.1851 - accuracy: 0.6452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7f4063630>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"LSTM_checkpoints/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 verbose=0,\n",
    "                                                 monitor='loss',\n",
    "                                                 mode='min')\n",
    "\n",
    "lstm.fit(x_data, y_data, epochs=30, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LjzFAUAwHMeu"
   },
   "outputs": [],
   "source": [
    "min_loss_cp = \"LSTM_checkpoints/cp.ckpt\"\n",
    "\n",
    "min_loss_lstm = keras.models.Sequential()\n",
    "min_loss_lstm.add(keras.layers.LSTM(units=256, input_shape=(window_size-1, 1)))\n",
    "min_loss_lstm.add(keras.layers.Dense(y_data.shape[1], activation=\"softmax\"))\n",
    "min_loss_lstm.load_weights(min_loss_cp)\n",
    "min_loss_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3UDrHUsJKuC",
    "outputId": "dc0ed05c-716a-477a-f935-78281908702a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object\n"
     ]
    }
   ],
   "source": [
    "init_text = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "\n",
    "remove = dict.fromkeys(map(ord, string.punctuation), ' ')\n",
    "processed_text = ' '.join(init_text.translate(remove).lower().split())\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-EDeUCeKoik",
    "outputId": "436d85bc-a845-4100-9487-48ec3fb16520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object which is the same as the shnple in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the state of affairs in the \n"
     ]
    }
   ],
   "source": [
    "test_input = processed_text[-99:]\n",
    "test_input_array = np.array([corpus_char_scaled_dict[x] for x in test_input])\n",
    "result = processed_text\n",
    "\n",
    "for i in range(1000):\n",
    "    data = np.reshape(test_input_array, (1, test_input_array.shape[0], 1)) #reshape the feed-in data\n",
    "    pred = min_loss_lstm.predict(data) #make predication\n",
    "    charIndex = np.argmax(pred) #find the index of output with max prob\n",
    "    pred_char = corpus_code_char_dict[charIndex] #translate the output to char\n",
    "    result += pred_char #append the predicted char to result\n",
    "\n",
    "    #append the previous pred_char to input text and get a new test_input_array\n",
    "    test_input += pred_char\n",
    "    test_input = test_input[-99:]\n",
    "    test_input_array = np.array([corpus_char_scaled_dict[x] for x in test_input])\n",
    "    \n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DSCI552 HW7 colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
